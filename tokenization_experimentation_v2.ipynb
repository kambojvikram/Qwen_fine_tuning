{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "qWob8dHppUVX"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def load(file):\n",
        "    with open(file, encoding=\"utf-8\") as f:\n",
        "        return [l.strip().lower() for l in f if l.strip()]\n",
        "\n",
        "words = set(load(\"en.txt\") + load(\"bad-words.txt\")*10000)\n",
        "\n",
        "# filter\n",
        "clean = [\n",
        "    w for w in words\n",
        "    if len(w) > 3 and re.fullmatch(r\"[a-z]+\", w)\n",
        "]\n",
        "\n",
        "IMPORTANT = {\n",
        "    \"fuck\": 1000,\n",
        "}\n",
        "\n",
        "with open(\"sp_train.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for w in clean:\n",
        "        boost = IMPORTANT.get(w, 150)\n",
        "        f.write((w + \" \") * boost + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "\n",
        "spm.SentencePieceTrainer.train(\n",
        "    input=\"sp_train.txt\",\n",
        "    model_prefix=\"custom_sp\",\n",
        "    vocab_size=3000,\n",
        "    model_type=\"bpe\",\n",
        "    character_coverage=1.0,\n",
        "    split_by_whitespace=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "dN4xb9tKps3b"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "URcg6OkvrbLk"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load(\"custom_sp.model\")\n",
        "\n",
        "tests = [\n",
        "    \"killforyou\",\n",
        "    \"fuckyour mother\",\n",
        "    \"sisterfucker\",\n",
        "    \"killeritems\",\n",
        "    'suckmydick',\n",
        "    'motherfuckerjews',\n",
        "    'xgspotforyou'\n",
        "]\n",
        "\n",
        "for t in tests:\n",
        "    print(t, \"->\", sp.encode(t, out_type=str))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si36LPXAqKDx",
        "outputId": "10c2e1d2-a0e5-4cf9-c3ee-f6b67d07d146"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "killforyou -> ['▁kill', 'f', 'or', 'you']\n",
            "fuckyour mother -> ['▁fuck', 'y', 'our', '▁mother']\n",
            "sisterfucker -> ['▁s', 'ist', 'er', 'fucker']\n",
            "killeritems -> ['▁killer', 'it', 'em', 's']\n",
            "suckmydick -> ['▁suckmy', 'dick']\n",
            "motherfuckerjews -> ['▁mother', 'fucker', 'j', 'ew', 's']\n",
            "xgspotforyou -> ['▁', 'x', 'g', 'spot', 'f', 'or', 'you']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "YQrsdWU5qOVx"
      },
      "execution_count": 81,
      "outputs": []
    }
  ]
}